{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e168fb22-386f-4721-aa92-9dc7e490905d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8ae9a815-6b2b-4502-b3c0-6a1a32e5df11",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Using incubator modules: jdk.incubator.vector\n",
      "Using Spark's default log4j profile: org/apache/spark/log4j2-defaults.properties\n",
      "25/08/12 17:52:05 WARN Utils: Your hostname, Omars-MacBook-Pro.local, resolves to a loopback address: 127.0.0.1; using 192.168.1.44 instead (on interface en0)\n",
      "25/08/12 17:52:05 WARN Utils: Set SPARK_LOCAL_IP if you need to bind to another address\n",
      "Using Spark's default log4j profile: org/apache/spark/log4j2-defaults.properties\n",
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "25/08/12 17:52:36 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n",
      "25/08/12 17:52:36 WARN Utils: Service 'SparkUI' could not bind on port 4040. Attempting port 4041.\n"
     ]
    }
   ],
   "source": [
    "spark=SparkSession.builder.appName(\"project\").getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6908e755-1706-4b41-84de-019a44610021",
   "metadata": {},
   "outputs": [],
   "source": [
    "df=spark.read.csv('sentiment_analysis.csv',header=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "1ff6bae5-9a01-4b02-9560-9fe72d9a899a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+-----+--------------------+\n",
      "| id|label|               tweet|\n",
      "+---+-----+--------------------+\n",
      "|  1|    0|#fingerprint #Pre...|\n",
      "|  2|    0|Finally a transpa...|\n",
      "|  3|    0|We love this! Wou...|\n",
      "|  4|    0|I'm wired I know ...|\n",
      "|  5|    1|What amazing serv...|\n",
      "|  6|    1|iPhone software u...|\n",
      "|  7|    0|Happy for us .. #...|\n",
      "|  8|    0|New Type C charge...|\n",
      "|  9|    0|Bout to go shoppi...|\n",
      "| 10|    0|Photo: #fun #self...|\n",
      "| 11|    1|hey #apple when y...|\n",
      "| 12|    1|Ha! Not heavy mac...|\n",
      "| 13|    1|Contemplating giv...|\n",
      "| 14|    0|I just made anoth...|\n",
      "| 15|    1|@shaqlockholmes @...|\n",
      "| 16|    0|From #DeepEllum t...|\n",
      "| 17|    0|Like and Share if...|\n",
      "| 18|    0|Go crazy !! #ipho...|\n",
      "| 19|    1|The reason I don'...|\n",
      "| 20|    1|How is the apple ...|\n",
      "+---+-----+--------------------+\n",
      "only showing top 20 rows\n"
     ]
    }
   ],
   "source": [
    "df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "9f1ff17b-c6cb-4b9e-bcab-a5d3102e5be4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import col"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "d682659b-af77-4089-9538-47a9e0c62322",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+\n",
      "|label|\n",
      "+-----+\n",
      "|    0|\n",
      "|    1|\n",
      "+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.select(\"label\").distinct().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "b33e8346-0b74-4264-aa7c-0c2709b52a5c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7920"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pyspark.sql.functions import col\n",
    "\n",
    "# Count tweets that are NOT null or empty\n",
    "df.filter(col(\"tweet\").isNotNull() & (col(\"tweet\") != \"\")).count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "9f099659-48ba-4f4c-ad05-47d7b55b89e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+\n",
      "|null_or_empty_tweets|\n",
      "+--------------------+\n",
      "|                   0|\n",
      "+--------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import col, when, count\n",
    "\n",
    "# Count how many rows have null or empty tweets\n",
    "df.select(\n",
    "    count(when(col(\"tweet\").isNull() | (col(\"tweet\") == \"\"), \"tweet\")).alias(\"null_or_empty_tweets\")\n",
    ").show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "229ac4b6-a6a0-48be-8264-951f6d38717d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import col, lower, regexp_replace,length,trim\n",
    "from pyspark.ml.feature import Tokenizer, StopWordsRemover, HashingTF, IDF, StringIndexer,Normalizer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "990206e5-178c-4952-932a-375fa0d2d3f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "df=df.withColumn('length',length(df['tweet']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "44c94ebd-6b37-41d5-b51d-79cfc9de26c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+-----+--------------------+------+\n",
      "| id|label|               tweet|length|\n",
      "+---+-----+--------------------+------+\n",
      "|  1|    0|#fingerprint #Pre...|   128|\n",
      "|  2|    0|Finally a transpa...|   131|\n",
      "|  3|    0|We love this! Wou...|   123|\n",
      "|  4|    0|I'm wired I know ...|   112|\n",
      "|  5|    1|What amazing serv...|   124|\n",
      "|  6|    1|iPhone software u...|    65|\n",
      "|  7|    0|Happy for us .. #...|   100|\n",
      "|  8|    0|New Type C charge...|   259|\n",
      "|  9|    0|Bout to go shoppi...|   130|\n",
      "| 10|    0|Photo: #fun #self...|   128|\n",
      "| 11|    1|hey #apple when y...|   124|\n",
      "| 12|    1|Ha! Not heavy mac...|   122|\n",
      "| 13|    1|Contemplating giv...|   116|\n",
      "| 14|    0|I just made anoth...|   133|\n",
      "| 15|    1|@shaqlockholmes @...|   127|\n",
      "| 16|    0|From #DeepEllum t...|   123|\n",
      "| 17|    0|Like and Share if...|   274|\n",
      "| 18|    0|Go crazy !! #ipho...|   121|\n",
      "| 19|    1|The reason I don'...|   134|\n",
      "| 20|    1|How is the apple ...|   115|\n",
      "+---+-----+--------------------+------+\n",
      "only showing top 20 rows\n"
     ]
    }
   ],
   "source": [
    "df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "aa7232be-7b36-4ed6-bf29-d1fc44ba1c2f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+------------------+\n",
      "|label|       avg(length)|\n",
      "+-----+------------------+\n",
      "|    0|137.04546996946047|\n",
      "|    1|104.65597235932873|\n",
      "+-----+------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.groupBy('label').mean('length').show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "8f44c651-ea75-47d6-82da-93fbd3e0e6b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+-----+\n",
      "|               tweet|count|\n",
      "+--------------------+-----+\n",
      "|@architecture_3de...|    3|\n",
      "+--------------------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import col, count\n",
    "\n",
    "duplicates = df.groupBy(\"tweet\") \\\n",
    "    .agg(count(\"tweet\").alias(\"count\")) \\\n",
    "    .filter(col(\"count\") > 1) \\\n",
    "    .orderBy(col(\"count\").desc())\n",
    "\n",
    "duplicates.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "6797bc29-aa07-4b57-b491-5ea18c0839ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.withColumn(\n",
    "    \"tweet\",\n",
    "    lower(regexp_replace(\"tweet_clean\", r\"http\\S+|@\\w+|#\\w+|[^a-zA-Z\\s]\", \"\"))\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "dff0e2d3-13d1-437f-9929-8ebc0c03fc22",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.withColumn(\"tweet_clean\", regexp_replace(\"tweet\", r\"\\bpictwitter\\w+\\b\", \"\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "88a297f7-2449-41e0-8288-db15fcfdf29a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import regexp_replace, trim\n",
    "\n",
    "df = df.withColumn(\"tweet_clean\", \n",
    "                        trim(regexp_replace(\"tweet\", r\"#|\\s+\", \" \")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "275c357e-ec61-4984-ba3e-892b350d9904",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import regexp_replace\n",
    "\n",
    "df = df.withColumn(\"tweet_clean\", regexp_replace(\"tweet\", r\"\\s{2,}\", \" \"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "a13d9f40-93f1-4dfc-a22b-0b59342c67b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+-----+--------------------+------+--------------------+--------------------+\n",
      "| id|label|               tweet|length|         tweet_clean|               words|\n",
      "+---+-----+--------------------+------+--------------------+--------------------+\n",
      "|  1|    0|                test|   128|                test|              [test]|\n",
      "|  2|    0|finally a transpa...|   131|finally a transpa...|[finally, a, tran...|\n",
      "|  3|    0|we love this woul...|   123|we love this woul...|[we, love, this, ...|\n",
      "|  4|    0|im wired i know i...|   112|im wired i know i...|[im, wired, i, kn...|\n",
      "|  5|    1|what amazing serv...|   124|what amazing serv...|[what, amazing, s...|\n",
      "|  6|    1|iphone software u...|    65|iphone software u...|[iphone, software...|\n",
      "|  7|    0|        happy for us|   100|        happy for us|    [happy, for, us]|\n",
      "|  8|    0|new type c charge...|   259|new type c charge...|[new, type, c, ch...|\n",
      "|  9|    0|bout to go shoppi...|   130|bout to go shoppi...|[bout, to, go, sh...|\n",
      "| 10|    0|               photo|   128|               photo|             [photo]|\n",
      "| 11|    1|hey when you make...|   124|hey when you make...|[hey, , when, you...|\n",
      "| 12|    1|ha not heavy mach...|   122|ha not heavy mach...|[ha, not, heavy, ...|\n",
      "| 13|    1|contemplating giv...|   116|contemplating giv...|[contemplating, g...|\n",
      "| 14|    0|i just made anoth...|   133|i just made anoth...|[i, just, made, a...|\n",
      "| 15|    1|the battery is so...|   127|the battery is so...|[the, battery, is...|\n",
      "| 16|    0|        from towards|   123|        from towards|   [from, , towards]|\n",
      "| 17|    0|like and share if...|   274|like and share if...|[like, and, share...|\n",
      "| 18|    0|            go crazy|   121|            go crazy|         [go, crazy]|\n",
      "| 19|    1|the reason i dont...|   134|the reason i dont...|[the, reason, i, ...|\n",
      "| 20|    1|how is the apple ...|   115|how is the apple ...|[how, is, the, ap...|\n",
      "+---+-----+--------------------+------+--------------------+--------------------+\n",
      "only showing top 20 rows\n"
     ]
    }
   ],
   "source": [
    "df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "b5f074a2-f738-4143-ab70-25a11d546f8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = Tokenizer(inputCol='tweet', outputCol='words')\n",
    "df = tokenizer.transform(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "044a01ca-3450-4c75-98f0-dc8306b2da8a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+-----+--------------------+------+--------------------+--------------------+\n",
      "| id|label|               tweet|length|         tweet_clean|               words|\n",
      "+---+-----+--------------------+------+--------------------+--------------------+\n",
      "|  1|    0|                test|   128|                test|              [test]|\n",
      "|  2|    0|finally a transpa...|   131|finally a transpa...|[finally, a, tran...|\n",
      "|  3|    0|we love this woul...|   123|we love this woul...|[we, love, this, ...|\n",
      "|  4|    0|im wired i know i...|   112|im wired i know i...|[im, wired, i, kn...|\n",
      "|  5|    1|what amazing serv...|   124|what amazing serv...|[what, amazing, s...|\n",
      "|  6|    1|iphone software u...|    65|iphone software u...|[iphone, software...|\n",
      "|  7|    0|        happy for us|   100|        happy for us|    [happy, for, us]|\n",
      "|  8|    0|new type c charge...|   259|new type c charge...|[new, type, c, ch...|\n",
      "|  9|    0|bout to go shoppi...|   130|bout to go shoppi...|[bout, to, go, sh...|\n",
      "| 10|    0|               photo|   128|               photo|             [photo]|\n",
      "| 11|    1|hey when you make...|   124|hey when you make...|[hey, , when, you...|\n",
      "| 12|    1|ha not heavy mach...|   122|ha not heavy mach...|[ha, not, heavy, ...|\n",
      "| 13|    1|contemplating giv...|   116|contemplating giv...|[contemplating, g...|\n",
      "| 14|    0|i just made anoth...|   133|i just made anoth...|[i, just, made, a...|\n",
      "| 15|    1|the battery is so...|   127|the battery is so...|[the, battery, is...|\n",
      "| 16|    0|        from towards|   123|        from towards|   [from, , towards]|\n",
      "| 17|    0|like and share if...|   274|like and share if...|[like, and, share...|\n",
      "| 18|    0|            go crazy|   121|            go crazy|         [go, crazy]|\n",
      "| 19|    1|the reason i dont...|   134|the reason i dont...|[the, reason, i, ...|\n",
      "| 20|    1|how is the apple ...|   115|how is the apple ...|[how, is, the, ap...|\n",
      "+---+-----+--------------------+------+--------------------+--------------------+\n",
      "only showing top 20 rows\n"
     ]
    }
   ],
   "source": [
    "df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "b44174ca-c418-4a60-950d-9b0545532b97",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------------------------------------------------------------------------------------------------------+\n",
      "|tweet                                                                                                             |\n",
      "+------------------------------------------------------------------------------------------------------------------+\n",
      "|test                                                                                                              |\n",
      "|finally a transparant silicon case thanks to my uncle                                                             |\n",
      "|we love this would you go                                                                                         |\n",
      "|im wired i know im george i was made that way                                                                     |\n",
      "|what amazing service apple wont even talk to me about a question i have unless i pay them for their stupid support|\n",
      "|iphone software update fucked up my phone big time stupid iphones                                                 |\n",
      "|happy for us                                                                                                      |\n",
      "|new type c charger cable new year cross young                                                                     |\n",
      "|bout to go shopping again listening to music                                                                      |\n",
      "|photo                                                                                                             |\n",
      "+------------------------------------------------------------------------------------------------------------------+\n",
      "only showing top 10 rows\n"
     ]
    }
   ],
   "source": [
    "df.select(\"tweet\").show(10,truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "569d5fcd-33a1-4f24-a0ae-b6823ffd4c70",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "25/08/12 18:09:30 WARN StopWordsRemover: Default locale set was [en_EG]; however, it was not found in available locales in JVM, falling back to en_US locale. Set param `locale` in order to respect another locale.\n"
     ]
    }
   ],
   "source": [
    "from pyspark.ml.feature import StopWordsRemover\n",
    "remover = StopWordsRemover(inputCol=\"words\", outputCol=\"filtered_words\")\n",
    "df= remover.transform(df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "85e0e301-cdc7-4ffd-bdc9-3b8d2d9315ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+-----+--------------------+------+--------------------+--------------------+--------------------+\n",
      "| id|label|               tweet|length|         tweet_clean|               words|      filtered_words|\n",
      "+---+-----+--------------------+------+--------------------+--------------------+--------------------+\n",
      "|  1|    0|                test|   128|                test|              [test]|              [test]|\n",
      "|  2|    0|finally a transpa...|   131|finally a transpa...|[finally, a, tran...|[finally, transpa...|\n",
      "|  3|    0|we love this woul...|   123|we love this woul...|[we, love, this, ...|          [love, go]|\n",
      "|  4|    0|im wired i know i...|   112|im wired i know i...|[im, wired, i, kn...|[im, wired, know,...|\n",
      "|  5|    1|what amazing serv...|   124|what amazing serv...|[what, amazing, s...|[amazing, service...|\n",
      "|  6|    1|iphone software u...|    65|iphone software u...|[iphone, software...|[iphone, software...|\n",
      "|  7|    0|        happy for us|   100|        happy for us|    [happy, for, us]|         [happy, us]|\n",
      "|  8|    0|new type c charge...|   259|new type c charge...|[new, type, c, ch...|[new, type, c, ch...|\n",
      "|  9|    0|bout to go shoppi...|   130|bout to go shoppi...|[bout, to, go, sh...|[bout, go, shoppi...|\n",
      "| 10|    0|               photo|   128|               photo|             [photo]|             [photo]|\n",
      "| 11|    1|hey when you make...|   124|hey when you make...|[hey, , when, you...|[hey, , make, new...|\n",
      "| 12|    1|ha not heavy mach...|   122|ha not heavy mach...|[ha, not, heavy, ...|[ha, heavy, machi...|\n",
      "| 13|    1|contemplating giv...|   116|contemplating giv...|[contemplating, g...|[contemplating, g...|\n",
      "| 14|    0|i just made anoth...|   133|i just made anoth...|[i, just, made, a...|[made, another, c...|\n",
      "| 15|    1|the battery is so...|   127|the battery is so...|[the, battery, is...|[battery, painful...|\n",
      "| 16|    0|        from towards|   123|        from towards|   [from, , towards]|         [, towards]|\n",
      "| 17|    0|like and share if...|   274|like and share if...|[like, and, share...|[like, share, wan...|\n",
      "| 18|    0|            go crazy|   121|            go crazy|         [go, crazy]|         [go, crazy]|\n",
      "| 19|    1|the reason i dont...|   134|the reason i dont...|[the, reason, i, ...|[reason, dont, on...|\n",
      "| 20|    1|how is the apple ...|   115|how is the apple ...|[how, is, the, ap...|[apple, store, gu...|\n",
      "+---+-----+--------------------+------+--------------------+--------------------+--------------------+\n",
      "only showing top 20 rows\n"
     ]
    }
   ],
   "source": [
    "df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "403225f4-9980-4810-a46a-ca0b540adcc4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+--------------------+\n",
      "|               tweet|      filtered_words|\n",
      "+--------------------+--------------------+\n",
      "|                test|              [test]|\n",
      "|finally a transpa...|[finally, transpa...|\n",
      "|we love this woul...|          [love, go]|\n",
      "|im wired i know i...|[im, wired, know,...|\n",
      "|what amazing serv...|[amazing, service...|\n",
      "|iphone software u...|[iphone, software...|\n",
      "|        happy for us|         [happy, us]|\n",
      "|new type c charge...|[new, type, c, ch...|\n",
      "|bout to go shoppi...|[bout, go, shoppi...|\n",
      "|               photo|             [photo]|\n",
      "|hey when you make...|[hey, , make, new...|\n",
      "|ha not heavy mach...|[ha, heavy, machi...|\n",
      "|contemplating giv...|[contemplating, g...|\n",
      "|i just made anoth...|[made, another, c...|\n",
      "|the battery is so...|[battery, painful...|\n",
      "|        from towards|         [, towards]|\n",
      "|like and share if...|[like, share, wan...|\n",
      "|            go crazy|         [go, crazy]|\n",
      "|the reason i dont...|[reason, dont, on...|\n",
      "|how is the apple ...|[apple, store, gu...|\n",
      "+--------------------+--------------------+\n",
      "only showing top 20 rows\n"
     ]
    }
   ],
   "source": [
    "df.select('tweet','filtered_words').show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "dc0fda50-d39d-4e35-b537-a76d0019b83b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+-----+--------------------+------+--------------------+--------------------+--------------------+\n",
      "| id|label|               tweet|length|         tweet_clean|               words|      filtered_words|\n",
      "+---+-----+--------------------+------+--------------------+--------------------+--------------------+\n",
      "|  1|    0|                test|   128|                test|              [test]|              [test]|\n",
      "|  2|    0|finally a transpa...|   131|finally a transpa...|[finally, a, tran...|[finally, transpa...|\n",
      "|  3|    0|we love this woul...|   123|we love this woul...|[we, love, this, ...|          [love, go]|\n",
      "|  4|    0|im wired i know i...|   112|im wired i know i...|[im, wired, i, kn...|[im, wired, know,...|\n",
      "|  5|    1|what amazing serv...|   124|what amazing serv...|[what, amazing, s...|[amazing, service...|\n",
      "|  6|    1|iphone software u...|    65|iphone software u...|[iphone, software...|[iphone, software...|\n",
      "|  7|    0|        happy for us|   100|        happy for us|    [happy, for, us]|         [happy, us]|\n",
      "|  8|    0|new type c charge...|   259|new type c charge...|[new, type, c, ch...|[new, type, c, ch...|\n",
      "|  9|    0|bout to go shoppi...|   130|bout to go shoppi...|[bout, to, go, sh...|[bout, go, shoppi...|\n",
      "| 10|    0|               photo|   128|               photo|             [photo]|             [photo]|\n",
      "| 11|    1|hey when you make...|   124|hey when you make...|[hey, , when, you...|[hey, make, new, ...|\n",
      "| 12|    1|ha not heavy mach...|   122|ha not heavy mach...|[ha, not, heavy, ...|[ha, heavy, machi...|\n",
      "| 13|    1|contemplating giv...|   116|contemplating giv...|[contemplating, g...|[contemplating, g...|\n",
      "| 14|    0|i just made anoth...|   133|i just made anoth...|[i, just, made, a...|[made, another, c...|\n",
      "| 15|    1|the battery is so...|   127|the battery is so...|[the, battery, is...|[battery, painful...|\n",
      "| 16|    0|        from towards|   123|        from towards|   [from, , towards]|           [towards]|\n",
      "| 17|    0|like and share if...|   274|like and share if...|[like, and, share...|[like, share, wan...|\n",
      "| 18|    0|            go crazy|   121|            go crazy|         [go, crazy]|         [go, crazy]|\n",
      "| 19|    1|the reason i dont...|   134|the reason i dont...|[the, reason, i, ...|[reason, dont, on...|\n",
      "| 20|    1|how is the apple ...|   115|how is the apple ...|[how, is, the, ap...|[apple, store, gu...|\n",
      "+---+-----+--------------------+------+--------------------+--------------------+--------------------+\n",
      "only showing top 20 rows\n"
     ]
    }
   ],
   "source": [
    "df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "14be066d-4b9d-46c1-90a1-9badabd4df93",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------------------------------------------------------------------------------------------------------+----------+\n",
      "|filtered_words                                                                                           |word_count|\n",
      "+---------------------------------------------------------------------------------------------------------+----------+\n",
      "|[test]                                                                                                   |1         |\n",
      "|[finally, transparant, silicon, case, thanks, uncle]                                                     |6         |\n",
      "|[love, go]                                                                                               |2         |\n",
      "|[im, wired, know, im, george, made, way]                                                                 |7         |\n",
      "|[amazing, service, apple, wont, even, talk, question, unless, pay, stupid, support]                      |11        |\n",
      "|[iphone, software, update, fucked, phone, big, time, stupid, iphones]                                    |9         |\n",
      "|[happy, us]                                                                                              |2         |\n",
      "|[new, type, c, charger, cable, new, year, cross, young]                                                  |9         |\n",
      "|[bout, go, shopping, listening, music]                                                                   |5         |\n",
      "|[photo]                                                                                                  |1         |\n",
      "|[hey, make, new, ipod, dont, make, new, color, inches, thinner, make, crash, every, five, fuckin, minite]|16        |\n",
      "|[ha, heavy, machinery, need, really, dropped, ball, design]                                              |8         |\n",
      "|[contemplating, giving, iphone, bandwagon, simply, new, androids]                                        |7         |\n",
      "|[made, another, crazy, purchase, lol, theory, work, hard, play, hard, lol]                               |11        |\n",
      "|[battery, painful, charge, overnight, lunchtime, battery, dead]                                          |7         |\n",
      "|[towards]                                                                                                |1         |\n",
      "|[like, share, want, d, phone, case, iphone]                                                              |7         |\n",
      "|[go, crazy]                                                                                              |2         |\n",
      "|[reason, dont, one, twittercomzpggdcazn]                                                                 |4         |\n",
      "|[apple, store, gunna, c, screens, monday, ur, fucking, apple, store]                                     |10        |\n",
      "+---------------------------------------------------------------------------------------------------------+----------+\n",
      "only showing top 20 rows\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import size\n",
    "\n",
    "df = df.withColumn(\"word_count\", size(\"filtered_words\"))\n",
    "\n",
    "df.select(\"filtered_words\", \"word_count\").show(truncate=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "4a6d24c3-3541-4eed-8fe7-ce7cc43ba053",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+-----+\n",
      "|word     |count|\n",
      "+---------+-----+\n",
      "|new      |876  |\n",
      "|iphone   |759  |\n",
      "|phone    |735  |\n",
      "|apple    |686  |\n",
      "|follow   |544  |\n",
      "|love     |414  |\n",
      "|rt       |321  |\n",
      "|day      |312  |\n",
      "|gain     |309  |\n",
      "|like     |309  |\n",
      "|im       |308  |\n",
      "|get      |293  |\n",
      "|back     |285  |\n",
      "|got      |279  |\n",
      "|happy    |239  |\n",
      "|one      |204  |\n",
      "|time     |200  |\n",
      "|photo    |198  |\n",
      "|cant     |188  |\n",
      "|everyone |179  |\n",
      "|make     |171  |\n",
      "|dont     |171  |\n",
      "|must     |168  |\n",
      "|finally  |165  |\n",
      "|followers|152  |\n",
      "|app      |150  |\n",
      "|update   |148  |\n",
      "|rts      |147  |\n",
      "|ipod     |142  |\n",
      "|work     |142  |\n",
      "|itunes   |139  |\n",
      "|today    |138  |\n",
      "|want     |135  |\n",
      "|case     |135  |\n",
      "|thanks   |131  |\n",
      "|ios      |127  |\n",
      "|good     |126  |\n",
      "|every    |125  |\n",
      "|fucking  |125  |\n",
      "|ipad     |125  |\n",
      "+---------+-----+\n",
      "only showing top 40 rows\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import explode, col\n",
    "\n",
    "# Explode filtered words into separate rows\n",
    "words_df = df.select(explode(col(\"filtered_words\")).alias(\"word\"))\n",
    "\n",
    "# Count and sort by frequency\n",
    "word_counts = words_df.groupBy(\"word\").count().orderBy(col(\"count\").desc())\n",
    "\n",
    "word_counts.show(40, truncate=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "a97a33b2-a712-4663-a5fc-f4a9a29fb8db",
   "metadata": {},
   "outputs": [],
   "source": [
    "hashingTF = HashingTF(inputCol=\"filtered_words\", outputCol=\"hashing\")\n",
    "df = hashingTF.transform(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "b394c475-e885-4fb5-bb56-fc1bfdf05433",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+-----+--------------------+------+--------------------+--------------------+--------------------+----------+--------------------+\n",
      "| id|label|               tweet|length|         tweet_clean|               words|      filtered_words|word_count|             hashing|\n",
      "+---+-----+--------------------+------+--------------------+--------------------+--------------------+----------+--------------------+\n",
      "|  1|    0|                test|   128|                test|              [test]|              [test]|         1|(262144,[188762],...|\n",
      "|  2|    0|finally a transpa...|   131|finally a transpa...|[finally, a, tran...|[finally, transpa...|         6|(262144,[7625,143...|\n",
      "|  3|    0|we love this woul...|   123|we love this woul...|[we, love, this, ...|          [love, go]|         2|(262144,[148675,1...|\n",
      "|  4|    0|im wired i know i...|   112|im wired i know i...|[im, wired, i, kn...|[im, wired, know,...|         7|(262144,[31015,51...|\n",
      "|  5|    1|what amazing serv...|   124|what amazing serv...|[what, amazing, s...|[amazing, service...|        11|(262144,[1696,437...|\n",
      "|  6|    1|iphone software u...|    65|iphone software u...|[iphone, software...|[iphone, software...|         9|(262144,[1696,612...|\n",
      "|  7|    0|        happy for us|   100|        happy for us|    [happy, for, us]|         [happy, us]|         2|(262144,[109156,1...|\n",
      "|  8|    0|new type c charge...|   259|new type c charge...|[new, type, c, ch...|[new, type, c, ch...|         9|(262144,[36225,49...|\n",
      "|  9|    0|bout to go shoppi...|   130|bout to go shoppi...|[bout, to, go, sh...|[bout, go, shoppi...|         5|(262144,[59009,10...|\n",
      "| 10|    0|               photo|   128|               photo|             [photo]|             [photo]|         1|(262144,[82583],[...|\n",
      "| 11|    1|hey when you make...|   124|hey when you make...|[hey, , when, you...|[hey, make, new, ...|        16|(262144,[12710,61...|\n",
      "| 12|    1|ha not heavy mach...|   122|ha not heavy mach...|[ha, not, heavy, ...|[ha, heavy, machi...|         8|(262144,[1797,254...|\n",
      "| 13|    1|contemplating giv...|   116|contemplating giv...|[contemplating, g...|[contemplating, g...|         7|(262144,[31732,79...|\n",
      "| 14|    0|i just made anoth...|   133|i just made anoth...|[i, just, made, a...|[made, another, c...|        11|(262144,[2437,148...|\n",
      "| 15|    1|the battery is so...|   127|the battery is so...|[the, battery, is...|[battery, painful...|         7|(262144,[11275,48...|\n",
      "| 16|    0|        from towards|   123|        from towards|   [from, , towards]|           [towards]|         1|(262144,[79497],[...|\n",
      "| 17|    0|like and share if...|   274|like and share if...|[like, and, share...|[like, share, wan...|         7|(262144,[6122,317...|\n",
      "| 18|    0|            go crazy|   121|            go crazy|         [go, crazy]|         [go, crazy]|         2|(262144,[113024,1...|\n",
      "| 19|    1|the reason i dont...|   134|the reason i dont...|[the, reason, i, ...|[reason, dont, on...|         4|(262144,[21823,87...|\n",
      "| 20|    1|how is the apple ...|   115|how is the apple ...|[how, is, the, ap...|[apple, store, gu...|        10|(262144,[41748,74...|\n",
      "+---+-----+--------------------+------+--------------------+--------------------+--------------------+----------+--------------------+\n",
      "only showing top 20 rows\n"
     ]
    }
   ],
   "source": [
    "df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "ec52d9b8-4a65-4001-b00d-b0a80db63997",
   "metadata": {},
   "outputs": [],
   "source": [
    "idf=IDF(inputCol='hashing',outputCol='feature')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "f1c6f7f8-9820-49e8-be4a-d8b4f14de038",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "idf_model=idf.fit(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "5c33a2f5-9b67-409a-abb8-70ce648020f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "rescale=idf_model.transform(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "acbe4045-f3d5-4bce-b551-a7f20022e57c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+--------------------+\n",
      "|label|             feature|\n",
      "+-----+--------------------+\n",
      "|    0|(262144,[188762],...|\n",
      "|    0|(262144,[7625,143...|\n",
      "|    0|(262144,[148675,1...|\n",
      "|    0|(262144,[31015,51...|\n",
      "|    1|(262144,[1696,437...|\n",
      "|    1|(262144,[1696,612...|\n",
      "|    0|(262144,[109156,1...|\n",
      "|    0|(262144,[36225,49...|\n",
      "|    0|(262144,[59009,10...|\n",
      "|    0|(262144,[82583],[...|\n",
      "|    1|(262144,[12710,61...|\n",
      "|    1|(262144,[1797,254...|\n",
      "|    1|(262144,[31732,79...|\n",
      "|    0|(262144,[2437,148...|\n",
      "|    1|(262144,[11275,48...|\n",
      "|    0|(262144,[79497],[...|\n",
      "|    0|(262144,[6122,317...|\n",
      "|    0|(262144,[113024,1...|\n",
      "|    1|(262144,[21823,87...|\n",
      "|    1|(262144,[41748,74...|\n",
      "+-----+--------------------+\n",
      "only showing top 20 rows\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "25/08/12 19:47:30 WARN DAGScheduler: Broadcasting large task binary with size 4.0 MiB\n"
     ]
    }
   ],
   "source": [
    "rescale.select('label','feature').show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "33051e94-6dd0-48c4-ba3f-24c42ce4e1f6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "8c249744-3bb4-4382-a860-7bd7c2ad61dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.classification import NaiveBayes \n",
    "from pyspark.ml import Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b40cd81d-4bf0-4884-8474-17c17a7af8ad",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "949d5ad7-6ca4-4649-9f6d-4d677da01b32",
   "metadata": {},
   "outputs": [],
   "source": [
    "nb=NaiveBayes()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e7c70d8-febf-44e1-ad1d-d187d7a96ca9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
